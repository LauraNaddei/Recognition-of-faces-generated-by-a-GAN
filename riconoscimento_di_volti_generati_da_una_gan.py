# -*- coding: utf-8 -*-
"""Riconoscimento di volti generati da una GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sa3VxrIIpJfbc1ZK-TCHZ7c9SPmixI5R

#####Carichiamo il dataset:
"""

!wget --user=corso --password=p2021corso http://www.grip.unina.it/download/corso/GANfacesDataset.zip
!unzip -q -n GANfacesDataset.zip

"""#####Escludiamo le immagini ProGAN: """

import os 
import shutil

os.makedirs("ProGAN") 

shutil.move("/content/GANfacesDataset/ProGAN256","ProGAN")

"""#####Dividiamo il dataset in tre subset, considerando il 70% per il training, il 10% per la validazione e il 20% per il test. Per farlo, sfruttiamo le funzionalità del modulo "splitfolders". """

!pip install split_folders

import splitfolders

input_folder = "GANfacesDataset"
output = "GANDataset"
splitfolders.ratio(input_folder, output, ratio=(.7,.1,.2))

"""#####Prepariamo i dati per la classificazione binaria, reale vs sintentico, usando le funzioni Keras ImageDataGenerator, insieme con il metodo flow_from_directory. Questo metodo prevede l'impiego di cartelle per validazione e addestramento. In ciascuna di esse, devono comparire tante sotto-cartelle, con le corrispondenti immagini, quante classi per la classificazione. 

"""

#TRAINING 

os.chdir("/content/GANDataset/train")
os.makedirs("vere")
os.makedirs("false")

shutil.move("pristine1024","vere")
shutil.move("pristine256","vere")

shutil.move("RelGAN256","false")
shutil.move("StartGAN256","false")
shutil.move("Style2GAN1024","false")
shutil.move("StyleGAN1024","false")

#VALIDAZIONE

os.chdir("/content/GANDataset/val")
os.makedirs("vere")
os.makedirs("false")

shutil.move("pristine1024","vere")
shutil.move("pristine256","vere")

shutil.move("RelGAN256","false")
shutil.move("StartGAN256","false")
shutil.move("Style2GAN1024","false")
shutil.move("StyleGAN1024","false")

#Importiamo i singoli moduli di interesse

from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.models import Model 
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt 
import numpy as np

img_height, img_width = (224,224) #dimensioni per le immagini in ingresso
batch_size = 64                   #dimesione del batch

train_data_dir = r"/content/GANDataset/train/" #percorso alla directory di training
valid_data_dir = r"/content/GANDataset/val/"   #percorso alla directory di validation

"""#####Definiamo la funzione di preprocessamento per le immagini in ingresso alla rete, così realizziamo data-augmentation sui SOLI dati di training nella forma di un blurring gaussiano, rotazioni randomatiche di multipli interni di 90°  e con un ritaglio al centro di 224x224 pixel."""

import cv2          #per farlo impieghiamo le funzionalità offerte dal modulo cv2

def crop_top(img):
  M,N,P = img.shape
  h = int(M/2) 
  k = int(N/2)
  crop_img = img[h-112:h+112, k-112:k+112] 
  return crop_img

def rotate(img):
  rows,cols = img.shape[:2]
  k = np.random.random_integers(low=1, high=4) #vogliamo rotazioni di multipli interi di 90° 
  M = cv2.getRotationMatrix2D((cols/2,rows/2),k*90,1) 
  dst = cv2.warpAffine(img,M,(cols,rows)) 
  return dst

def blur(img):
  img = crop_top(img)
  img = rotate(img)
  
  i=np.random.uniform(0.0,3.0) #sigma varia in un intervallo di reali in maniera randomatica
  k = np.random.randint(low=6*i+1)
  if k%2==1:                                #se k è dispari, ok
    y=cv2.GaussianBlur(img,(k,k),sigmaX=i)
    return y
  else:                                     #k è pari, allora rendo dispari le dimensione della finestra scorrevole. 
    y=cv2.GaussianBlur(img,(k+1,k+1),sigmaX=i)
    return y

#Creiamo il generatore per il training: 

train_datagen = image.ImageDataGenerator(
    rescale=1/255.0,                        #con questo parametro riportiamo le immagini nel range [0,1] (sono immagini a colori)
    rotation_range=90,
    preprocessing_function=blur)

#train_datagen = image.ImageDataGenerator(
#    rescale=1/255.0,                       
#   rotation_range=90,
#    zca_whitening=False,
#    zca_epsilon=1e-06,
#    shear_range=0.2, 
#    preprocessing_function=blur)          #si è tentati di irrobustire la fase di pre-processamento, distorcendo le immagini e rendendole più luminose, tuttavia non sono stati riscontrati miglioramenti significativi in termini di robustezza
                                          
train_generator = train_datagen.flow_from_directory(
    train_data_dir, 
    target_size=(img_height, img_width),
    batch_size=batch_size, 
    class_mode='categorical')                         #ovvero, rappresentazione one-hot: ogni etichetta rappresentata come un vettore di lunghezza pari al numero di classi

#Creiamo il generatore per la validazione:

valid_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

valid_generator = valid_datagen.flow_from_directory(
    valid_data_dir, 
    target_size=(img_height, img_width),
    batch_size=batch_size, 
    class_mode='categorical')

#Definiamo la funzione di scheduling per il learning rate: 

from math import exp

def scheduler(epoch, lr):
  if epoch < 2:             
    return lr
  else:                     # a partire dalla seconda epoca decrementiamo il lr di 1e-0.1
    return lr * exp(-0.1)

"""#####Adoperiamo ResNet50 come modello base della nostra rete. Preaddestrata su ImageNet, ne escludiamo gli ultimi strati fully-connected (per poi sostituirli con 1-2 strati Dense, con cui particolarizziamo la backbone al nostro caso specifico) e ne "congeliamo" i primi 35. """

base_model= ResNet50(weights='imagenet', input_shape=(img_height, img_width, 3), include_top=False)

model = Sequential()                      #costruiamo la rete sequenzialmente 
model.add(base_model) 
model.add(GlobalAveragePooling2D())
#model.add(Dropout(0.2))
#model.add(Dense(1024, activation='relu'))
#model.add(Dropout(0.2)) #escludo random 5 input ad ogni ciclo di update.
model.add(Dense(2, activation='softmax')) #vogliamo una distribuzione di probabilità =>softmax.

model.summary()

#abbiamo sperimentato inserendo strati di dropout tra i 2 dense e tra lo strato di pooling e il primo dense, non abbiamo, tuttavia, riscontrato cambiamenti 
#in positivo delle prestazioni

for layer in base_model.layers[:35]: #rendiamo non addestrabili i primi 35 strati della rete
  layer.trainable = False

"""#####Usiamo l'ottimizzatore Adam, nella sua variante AMSgrad in fase di compilazione e la categorical cross-entropy per la funzione di loss. """

opt = Adam(learning_rate=2e-05, amsgrad=True) #provare anche con 3e-05
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy', 'AUC'])
round(model.optimizer.lr.numpy(), 5)

callback = LearningRateScheduler(scheduler, verbose=1)
history = model.fit_generator(train_generator, epochs=12, verbose=1, callbacks=[callback], validation_data=valid_generator) #addestriamo
round(model.optimizer.lr.numpy(), 5)

"""#####Riportiamo l'andamento delle metriche valutate: """

#ACCURACY: 

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

#AREA UNDER ROC CURVE: 

plt.plot(history.history['auc'])
plt.plot(history.history['val_auc'])
plt.title('model auc')
plt.ylabel('auc')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

#LOSS FUNCTION: 

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""#####FASE DI TEST: """

os.chdir("/content/GANDataset/test")
os.makedirs("pauso")
os.makedirs("vere")
os.makedirs("false")

#Per una prima fase di test su RelGAN256:

shutil.move("pristine1024","vere")
shutil.move("pristine256","vere")

shutil.move("StartGAN256","pauso")
shutil.move("Style2GAN1024","pauso")
shutil.move("StyleGAN1024","pauso")

shutil.move("RelGAN256","false")

shutil.move("pauso", "/content")

test_data_dir = r"/content/GANDataset/test"    #percorso alla directory di test

#Creiamo il generatore per il test: 

test_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height,img_width),
    batch_size=batch_size,
    class_mode='categorical')

#Predizione e valutazione delle metriche: 

predictions = model.predict(test_generator,verbose=1)
test_loss, test_acc, test_auc = model.evaluate(test_generator, verbose=1)
print('\nTest accuracy: {}, \nArea under curve: {} '.format(test_acc, test_auc))

"""#####Seconda GAN."""

#Fase di test sulle StartGAN256:

os.chdir("/content/pauso")
shutil.move("StartGAN256","/content/GANDataset/test/false")

os.chdir("/content/GANDataset/test/false")
shutil.move("RelGAN256","/content/pauso")

test_data_dir = r"/content/GANDataset/test"    #percorso alla directory di test

#Creiamo il generatore per il test: 

test_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height,img_width),
    batch_size=batch_size,
    class_mode='categorical')

#Predizione e valutazione delle metriche: 

predictions = model.predict(test_generator,verbose=1)
test_loss, test_acc, test_auc = model.evaluate(test_generator, verbose=1)
print('\nTest accuracy: {}, \nArea under curve: {} '.format(test_acc, test_auc))

"""#####Terza GAN."""

#Fase di test sulle StyleGAN1024:

os.chdir("/content/pauso")
shutil.move("StyleGAN1024","/content/GANDataset/test/false")

os.chdir("/content/GANDataset/test/false")
shutil.move("StartGAN256","/content/pauso")

test_data_dir = r"/content/GANDataset/test"    #percorso alla directory di test

#Creiamo il generatore per il test: 

test_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height,img_width),
    batch_size=batch_size,
    class_mode='categorical')

#Predizione e valutazione delle metriche: 

predictions = model.predict(test_generator,verbose=1)
test_loss, test_acc, test_auc = model.evaluate(test_generator, verbose=1)
print('\nTest accuracy: {}, \nArea under curve: {} '.format(test_acc, test_auc))

"""#####Quarta GAN: """

#Fase di test sulle Style2GAN1024:

os.chdir("/content/pauso")
shutil.move("Style2GAN1024","/content/GANDataset/test/false")

os.chdir("/content/GANDataset/test/false")
shutil.move("StyleGAN1024","/content/pauso")

test_data_dir = r"/content/GANDataset/test"

#Creiamo il generatore per il test: 

test_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height,img_width),
    batch_size=batch_size,
    class_mode='categorical')

#Predizione e valutazione delle metriche: 

predictions = model.predict(test_generator,verbose=1)
test_loss, test_acc, test_auc = model.evaluate(test_generator, verbose=1)
print('\nTest accuracy: {}, \nArea under curve: {} '.format(test_acc, test_auc))

"""#####Analisi di robustezza: """

#Fase di test sulle ProGAN256:

os.chdir("/content")
shutil.move("ProGAN","/content/GANDataset/test/false")

os.chdir("/content/GANDataset/test/false")
shutil.move("Style2GAN1024","/content/pauso")

test_data_dir = r"/content/GANDataset/test"

#Creiamo il generatore per il test: 

test_datagen = image.ImageDataGenerator(
    rescale=1/255.0,
    preprocessing_function=crop_top)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height,img_width),
    batch_size=batch_size,
    class_mode='categorical')

#Predizione e valutazione delle metriche: 

predictions = model.predict(test_generator,verbose=1)
test_loss, test_acc, test_auc = model.evaluate(test_generator, verbose=1)
print('\nTest accuracy: {}, \nArea under curve: {} '.format(test_acc, test_auc))

"""#####Codice per la fase di test "in the wild": """

img = image.load_img('filename.png', target_size = (img_width, img_height)) #in luogo di filename inserire il nome di un'immagine preventivamente caricata in colab
img = image.img_to_array(img) #convertiamo l'immagine in un numpy array 
img = np.expand_dims(img, axis = 0) #si espandono le dimensioni dell'array nella direzione orizzonatale

y_pred = model.predict(img)

plt.figure()
plt.bar(np.arange(2), y_pred[0])
plt.show()